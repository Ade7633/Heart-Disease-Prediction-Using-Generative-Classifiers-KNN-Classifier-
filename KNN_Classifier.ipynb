{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba039ff",
   "metadata": {},
   "source": [
    "## Title: Heart Disease Prediction Using Generative Classifiers (KNN Classifier) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64813d9",
   "metadata": {},
   "source": [
    "# **Step 1: Import Necessary Python Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f355248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import exp, sqrt, pi\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4fc9e2",
   "metadata": {},
   "source": [
    "# **Step 2: Load Dataset (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9699aba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b689507",
   "metadata": {},
   "source": [
    "# Step 3: Understanding the UCI Heart Disease Dataset\n",
    "\n",
    "Let's now take a look at our dataset attributes and understand their meaning and significance.\n",
    "\n",
    "\n",
    "| Attribute Name | Type | Description |\n",
    "|-----------------------|----------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| id | Discrete | Unique identity for each patient |\n",
    "| age | Continuous | Represents age of the patient in years|\n",
    "| sex  | Categorical | Represents male or female  <br>(1 = male, 0 = female) |\n",
    "| dataset| Categorical |   Represents the place of study <br>(0:Cleveland, 1:Hungary, 2:Switzerland, 3:VA Long Beach) |\n",
    "| cp| Categorical |   Represents the chest pain type <br>(0: asymptomatic, 1: atypical angina, 2: non-anginal pain, 3: typical angina) |\n",
    "| trestbps | Continuous | resting blood pressure  (in mm Hg on admission to the hospital) |\n",
    "| chol | Continuous | serum cholesterol  (in mg/dl) |\n",
    "| fbs  | Categorical | Represents if fasting blood sugar > 120 mg/dl <br>(0 = false, 1 = true)|\n",
    "| restecg  | Categorical | Represents the resting electrocardiographic results <br>(0: showing probable or definite left ventricular hypertrophy by Estesâ€™ criteria, 1: normal, 2: having ST-T wave abnormality)|\n",
    "| thalach | Continuous | The maximum heart rate achieved |\n",
    "| exang  | Categorical | Represents the exercise-induced angina <br>(0 = false, 1 = true)|\n",
    "| oldpeak | Continuous | ST depression induced by exercise relative to rest |\n",
    "| slope  | Categorical | Represents the  slope of the peak exercise ST segment <br>(0: downsloping; 1: flat; 2: upsloping)|\n",
    "| ca | Continuous | number of major vessels (0-3) colored by fluoroscopy |\n",
    "| thal | Categorical | Represents <br>(0 = normal, 1 = fixed defect, 2 = reversible defect) |\n",
    "| num | Discrete | Represents the class label or predicted attribute where 0 indicates no heart disease and 1, 2, 3, and 4 represent the different stages of heart disease. <br>(0,1,2,3,4) |\n",
    "\n",
    "We have a total of 14 features and our objective is to predict if the patient has a heart disease. Hence we will be building and interpreting a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21cd583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e757af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86494152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "age           0\n",
       "sex           0\n",
       "dataset       0\n",
       "cp            0\n",
       "trestbps     59\n",
       "chol         30\n",
       "fbs          90\n",
       "restecg       2\n",
       "thalch       55\n",
       "exang        55\n",
       "oldpeak      62\n",
       "slope       309\n",
       "ca          611\n",
       "thal        486\n",
       "num           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c5074",
   "metadata": {},
   "source": [
    "# **Step 4: Compute K-Nearest Neighbors Classifier Without Sklearn**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b6c9e",
   "metadata": {},
   "source": [
    "**Step 4a: Handling Missinag values by filling continuous/float columns with mean and categorical/object columns with mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbadce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    mean_value = df[column].mean()\n",
    "    df[column] = df[column].fillna(mean_value) \n",
    "    \n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    mode_value = df[column].mode()[0]  # Get the first mode if there are multiple\n",
    "    df[column] = df[column].fillna(mode_value).infer_objects(copy=False)  # Assign back to the DataFrame and infer data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08889c20",
   "metadata": {},
   "source": [
    "**Step 4b: Scale continous variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1136b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
    "\n",
    "for column in columns_to_scale:\n",
    "    mean_value = df[column].mean()  # Calculate mean, ignoring NaNs\n",
    "    std_value = df[column].std()    # Calculate standard deviation, ignoring NaNs\n",
    "    df[column] = (df[column] - mean_value) / std_value  # Apply scaling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604f379",
   "metadata": {},
   "source": [
    "**Step 4c: One Hot Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e67b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping dictionary\n",
    "sex_mapping = {'Male': 1, 'Female': 0}\n",
    "\n",
    "# Map the values in the 'sex' column using the mapping dictionary and if the value is not 'M' or 'F', assign as 2\n",
    "df['sex'] = df['sex'].map(lambda x: sex_mapping.get(x, 2))\n",
    "\n",
    "print(df['sex'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf030b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#Define the mapping dictionary\n",
    "dataset_mapping = {'Cleveland': 0, 'Hungary': 1 , 'Switzerland': 2 , 'VA Long Beach': 3}\n",
    "                                                             \n",
    "# Map the values in the column using the mapping dictionary and if the value is not listed in the mapping assign as 4\n",
    "df['dataset'] = df['dataset'].map(lambda x: dataset_mapping.get(x, 4))\n",
    "\n",
    "print(df['dataset'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a95b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#Define the mapping dictionary\n",
    "cp_mapping = {'asymptomatic': 0, 'atypical angina': 1 , 'non-anginal': 2 , 'typical angina': 3}\n",
    "                                                             \n",
    "# Map the values in the column using the mapping dictionary and if the value is not listed in the mapping assign as 4\n",
    "df['cp'] = df['cp'].map(lambda x: cp_mapping.get(x, 4))\n",
    "\n",
    "print(df['cp'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e266593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#Define the mapping dictionary\n",
    "fbs_mapping = {True: 0, False: 1}\n",
    "                                                             \n",
    "# Map the values in the column using the mapping dictionary and if the value is not listed in the mapping assign as 4\n",
    "df['fbs'] = df['fbs'].map(lambda x: fbs_mapping.get(x, 2))\n",
    "\n",
    "print(df['fbs'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ebc881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#Define the mapping dictionary\n",
    "restecg_mapping = {'lv hypertrophy':0, 'normal' :1, 'st-t abnormality':2}\n",
    "                                                             \n",
    "# Map the values in the column using the mapping dictionary and if the value is not listed in the mapping assign as 4\n",
    "df['restecg'] = df['restecg'].map(lambda x: restecg_mapping.get(x, 3))\n",
    "\n",
    "print(df['restecg'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af65d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping dictionary\n",
    "exang_mapping = {True: 0, False: 1}\n",
    "                                                             \n",
    "# Map the values in the column using the mapping dictionary and if the value is not listed in the mapping assign as 4\n",
    "df['exang'] = df['exang'].map(lambda x: exang_mapping.get(x, 2))\n",
    "\n",
    "print(df['exang'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ae36687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#Define the mapping dictionary\n",
    "slope_mapping = {'downsloping':0, 'flat' :1, 'upsloping':2}\n",
    "                                                             \n",
    "# Map the values in the column using the mapping dictionary and if the value is not listed in the mapping assign as 4\n",
    "df['slope'] = df['slope'].map(lambda x: slope_mapping.get(x, 3))\n",
    "\n",
    "print(df['slope'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e90d832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#Define the mapping dictionary\n",
    "thal_mapping = {'fixed defect':0, 'normal' :1, 'reversable defect':2}\n",
    "                                                             \n",
    "# Map the values in the column using the mapping dictionary and if the value is not listed in the mapping assign as 4\n",
    "df['thal'] = df['thal'].map(lambda x: thal_mapping.get(x, 3))\n",
    "\n",
    "print(df['thal'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "617d7aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.697662</td>\n",
       "      <td>0.310852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495429</td>\n",
       "      <td>1</td>\n",
       "      <td>1.348688</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.248692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.431255</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.510939</td>\n",
       "      <td>0.797279</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.175316</td>\n",
       "      <td>0</td>\n",
       "      <td>0.589512</td>\n",
       "      <td>1</td>\n",
       "      <td>4.289765</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.431255</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.657801</td>\n",
       "      <td>0.274140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.339943</td>\n",
       "      <td>0</td>\n",
       "      <td>1.633379</td>\n",
       "      <td>1</td>\n",
       "      <td>2.443613</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.751875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.115616</td>\n",
       "      <td>0.466876</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.967275</td>\n",
       "      <td>1</td>\n",
       "      <td>2.487452</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.248692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.327458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.115616</td>\n",
       "      <td>0.044693</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.370581</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494615</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.248692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       age  sex  dataset  cp  trestbps      chol  fbs  restecg    thalch  \\\n",
       "0   1  1.006838    1        0   3  0.697662  0.310852    0        0  0.495429   \n",
       "1   2  1.431255    1        0   0  1.510939  0.797279    1        0 -1.175316   \n",
       "2   3  1.431255    1        0   0 -0.657801  0.274140    1        0 -0.339943   \n",
       "3   4 -1.751875    1        0   2 -0.115616  0.466876    1        1  1.967275   \n",
       "4   5 -1.327458    0        0   1 -0.115616  0.044693    1        0  1.370581   \n",
       "\n",
       "   exang   oldpeak  slope        ca  thal  num  \n",
       "0      1  1.348688      0 -1.248692     0    0  \n",
       "1      0  0.589512      1  4.289765     1    2  \n",
       "2      0  1.633379      1  2.443613     2    1  \n",
       "3      1  2.487452      0 -1.248692     1    0  \n",
       "4      1  0.494615      2 -1.248692     1    0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9681fb",
   "metadata": {},
   "source": [
    "**Step 4d: Functions to compute statistics and probablities of KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21c7c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Step 1: Shuffle the dataset\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Split into training, validation, and test sets (60:20:20)\n",
    "train_size = int(0.6 * len(df_shuffled))\n",
    "val_size = int(0.2 * len(df_shuffled))\n",
    "\n",
    "train_set = df_shuffled[:train_size]\n",
    "val_set = df_shuffled[train_size:train_size + val_size]\n",
    "test_set = df_shuffled[train_size + val_size:]\n",
    "\n",
    "# Separate features and labels for training, validation, and test sets\n",
    "X_train = train_set.drop(columns=['id', 'num'])  # Exclude 'id' and 'num'\n",
    "y_train = train_set['num']\n",
    "\n",
    "X_val = val_set.drop(columns=['id', 'num'])\n",
    "y_val = val_set['num']\n",
    "\n",
    "X_test = test_set.drop(columns=['id', 'num'])\n",
    "y_test = test_set['num']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95b2bab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set for k=1: 0.45\n",
      "Accuracy on validation set for k=2: 0.45\n",
      "Accuracy on validation set for k=3: 0.49\n",
      "Accuracy on validation set for k=4: 0.50\n",
      "Accuracy on validation set for k=5: 0.54\n",
      "Accuracy on validation set for k=6: 0.52\n",
      "Accuracy on validation set for k=7: 0.53\n",
      "Accuracy on validation set for k=8: 0.52\n",
      "Accuracy on validation set for k=9: 0.50\n",
      "Accuracy on validation set for k=10: 0.50\n",
      "Accuracy on validation set for k=11: 0.52\n",
      "Accuracy on validation set for k=12: 0.53\n",
      "Best k value: 5\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Euclidean distance between two data points\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "\n",
    "# Function to find the k nearest neighbors\n",
    "def get_neighbors(X_train, y_train, test_point, k):\n",
    "    distances = []\n",
    "    for i in range(len(X_train)):\n",
    "        distance = euclidean_distance(X_train.iloc[i], test_point)\n",
    "        distances.append((y_train.iloc[i], distance))\n",
    "    \n",
    "    # Sort the distances and select the k nearest neighbors\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    neighbors = [distances[i][0] for i in range(k)]\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "# Function to predict the class of a test point\n",
    "def predict_class_knn(X_train, y_train, test_point, k):\n",
    "    neighbors = get_neighbors(X_train, y_train, test_point, k)\n",
    "    most_common = Counter(neighbors).most_common(1)\n",
    "    return most_common[0][0]\n",
    "\n",
    "# Function to compute accuracy\n",
    "def compute_accuracy(X_train, y_train, X_test, y_test, k):\n",
    "    correct = 0\n",
    "    for i in range(len(X_test)):\n",
    "        predicted_class = predict_class_knn(X_train, y_train, X_test.iloc[i], k)\n",
    "        actual_class = y_test.iloc[i]\n",
    "        if predicted_class == actual_class:\n",
    "            correct += 1\n",
    "    return correct / len(X_test)\n",
    "\n",
    "# Step 3: Tune the hyperparameter k using the validation set\n",
    "#k_values = [2, 3, 4, 5,6,7,8,9,10]\n",
    "best_k = None\n",
    "best_accuracy = 0\n",
    "\n",
    "#for k in k_values:\n",
    "for k in range(3,13):\n",
    "    accuracy = compute_accuracy(X_train, y_train, X_val, y_val, k)\n",
    "    print(f'Accuracy on validation set for k={k}: {accuracy :.2f}')\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(f'Best k value: {best_k}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60331ce",
   "metadata": {},
   "source": [
    "**Step 4e: Functions to compute the confusion matrix for KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02848acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 - Accuracy: 0.82, Precision: 0.80, Recall: 0.80, F-Score: 0.80\n",
      "Class 1 - Accuracy: 0.77, Precision: 0.57, Recall: 0.65, F-Score: 0.61\n",
      "Class 2 - Accuracy: 0.84, Precision: 0.11, Recall: 0.12, F-Score: 0.12\n",
      "Class 3 - Accuracy: 0.79, Precision: 0.14, Recall: 0.13, F-Score: 0.14\n",
      "Class 4 - Accuracy: 0.96, Precision: 1.00, Recall: 0.12, F-Score: 0.22\n",
      " \n",
      "Overall Accuracy on the test set: 0.83\n",
      "Average Precision: 0.53\n",
      "Average Recall: 0.37\n",
      "Average F-Score: 0.38\n"
     ]
    }
   ],
   "source": [
    "# Function to compute confusion matrix for multi-class classification\n",
    "def compute_confusion_matrix_knn(X_train, y_train, X_test, y_test, k):\n",
    "    # Initialize counts for True Positives, True Negatives, False Positives, and False Negatives\n",
    "    num_classes = len(set(y_train))  # Dynamically find the number of classes from training labels\n",
    "    True_positives = [0] * num_classes\n",
    "    True_negatives = [0] * num_classes\n",
    "    False_positives = [0] * num_classes\n",
    "    False_negatives = [0] * num_classes\n",
    "\n",
    "    # Loop through each test example\n",
    "    for i in range(len(X_test)):\n",
    "        example_data_point = X_test.iloc[i]\n",
    "        actual_class = y_test.iloc[i]\n",
    "        predicted_class = predict_class_knn(X_train, y_train, example_data_point, k)\n",
    "\n",
    "        # Update confusion matrix based on predicted and actual classes\n",
    "        if predicted_class == actual_class:\n",
    "            True_positives[actual_class] += 1\n",
    "        else:\n",
    "            False_positives[predicted_class] += 1\n",
    "            False_negatives[actual_class] += 1\n",
    "\n",
    "    # Calculate True Negatives for each class\n",
    "    for j in range(num_classes):\n",
    "        True_negatives[j] = len(X_test) - (True_positives[j] + False_positives[j] + False_negatives[j])\n",
    "\n",
    "    # Compute class-specific performance metrics\n",
    "    class_specific_accuracy = [(True_positives[j] + True_negatives[j]) / (True_positives[j] + True_negatives[j] + False_positives[j] + False_negatives[j]) if (True_positives[j] + True_negatives[j] + False_positives[j] + False_negatives[j]) > 0 else 0 for j in range(num_classes)]\n",
    "\n",
    "    class_specific_precision = [True_positives[j] / (True_positives[j] + False_positives[j]) if (True_positives[j] + False_positives[j]) > 0 else 0 for j in range(num_classes)]\n",
    "    \n",
    "    class_specific_recall = [True_positives[j] / (True_positives[j] + False_negatives[j]) if (True_positives[j] + False_negatives[j]) > 0 else 0 for j in range(num_classes)]\n",
    "    \n",
    "    class_specific_FScore = [2 * class_specific_precision[j] * class_specific_recall[j] / (class_specific_precision[j] + class_specific_recall[j]) if (class_specific_precision[j] + class_specific_recall[j]) > 0 else 0 for j in range(num_classes)]\n",
    "\n",
    "    # Compute overall model performance\n",
    "    Average_accuracy = sum(class_specific_accuracy) / num_classes\n",
    "    Average_precision = sum(class_specific_precision) / num_classes\n",
    "    Average_recall = sum(class_specific_recall) / num_classes\n",
    "    Average_FScore = sum(class_specific_FScore) / num_classes\n",
    "\n",
    "    return {\n",
    "        \"Overall Accuracy\": Average_accuracy,\n",
    "        \"Average Precision\": Average_precision,\n",
    "        \"Average Recall\": Average_recall,\n",
    "        \"Average F-Score\": Average_FScore,\n",
    "        \"Class-Specific Metrics\": {\n",
    "            \"Accuracy\": class_specific_accuracy,\n",
    "            \"Precision\": class_specific_precision,\n",
    "            \"Recall\": class_specific_recall,\n",
    "            \"F-Score\": class_specific_FScore\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example: Call the function to compute the confusion matrix on the test set\n",
    "k = 5\n",
    "metrics = compute_confusion_matrix_knn(X_train, y_train, X_test, y_test, k)\n",
    "\n",
    "\n",
    "# Print Precision, Recall, and F1 Score for each class\n",
    "for i in range(len(metrics[\"Class-Specific Metrics\"][\"Accuracy\"])):\n",
    "    print(f'Class {i} - Accuracy: {metrics[\"Class-Specific Metrics\"][\"Accuracy\"][i]:.2f}, '\n",
    "          f'Precision: {metrics[\"Class-Specific Metrics\"][\"Precision\"][i]:.2f}, '\n",
    "          f'Recall: {metrics[\"Class-Specific Metrics\"][\"Recall\"][i]:.2f}, '\n",
    "          f'F-Score: {metrics[\"Class-Specific Metrics\"][\"F-Score\"][i]:.2f}')\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "\n",
    "# Print the overall performance metrics\n",
    "print(f'Overall Accuracy on the test set: {metrics[\"Overall Accuracy\"]:.2f}')\n",
    "print(f'Average Precision: {metrics[\"Average Precision\"]:.2f}')\n",
    "print(f'Average Recall: {metrics[\"Average Recall\"]:.2f}')\n",
    "print(f'Average F-Score: {metrics[\"Average F-Score\"]:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
